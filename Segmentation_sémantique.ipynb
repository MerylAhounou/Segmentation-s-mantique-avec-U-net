{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGQrjhh0gmXM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "AGQrjhh0gmXM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZxY1LQg4El"
      },
      "source": [
        "# Chargement des librairies"
      ],
      "id": "ywZxY1LQg4El"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uBhc7wFiBeU"
      },
      "outputs": [],
      "source": [
        "%pip install pynrrd"
      ],
      "id": "8uBhc7wFiBeU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wypk6z2QxRNL"
      },
      "outputs": [],
      "source": [
        "%pip install pydicom"
      ],
      "id": "Wypk6z2QxRNL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f721966"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import nrrd as nd\n",
        "import pandas as pd \n",
        "import random \n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import matplotlib.patches as mpatches\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pydicom import dcmread \n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import *\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import image\n",
        "from tensorflow.keras import backend as K\n",
        "from enum import Enum\n",
        "from PIL import Image"
      ],
      "id": "5f721966"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtoI7gCiOq2E"
      },
      "source": [
        "# Constantes"
      ],
      "id": "YtoI7gCiOq2E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1imNG1Ost8"
      },
      "outputs": [],
      "source": [
        "INPUTS_PATH = \"/content/drive/MyDrive/Segmentation sémantique/Inputs\"\n",
        "OUTPUTS_PATH = \"/content/drive/MyDrive/Segmentation sémantique/Outputs\"\n",
        "\n",
        "# La taille de l'image doit etre multiple de 16 parce que la première couche de convolution à des filtres de taille 16\n",
        "IMAGE_HEIGHT = 192\n",
        "IMAGE_WIDHT = 192\n",
        "\n",
        "NUM_CLASSES = 3"
      ],
      "id": "3e1imNG1Ost8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMzzc0DovqqS"
      },
      "source": [
        "# Fonctions"
      ],
      "id": "cMzzc0DovqqS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBML2VDFvsPF"
      },
      "outputs": [],
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    # first layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # second layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x"
      ],
      "id": "wBML2VDFvsPF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IjmbY1POSKL"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32), [-1])\n",
        "    y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32), [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)"
      ],
      "id": "1IjmbY1POSKL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vH5Lgt-vsyc"
      },
      "outputs": [],
      "source": [
        "def get_unet(input_img, n_filters = 32, dropout = 0.1, batchnorm = True):\n",
        "    \"\"\"Function to define the UNET Model\"\"\"\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "    \n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "    \n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "    \n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    # Expansive Path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(NUM_CLASSES, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs], name=\"U-net\")\n",
        "    return model"
      ],
      "id": "1vH5Lgt-vsyc"
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_inputs(img):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  img = np.squeeze(img)\n",
        "  for x,y in [(x,y) for x in range(img.shape[0]) for y in range(img.shape[1])]:\n",
        "      j = img[x,y]\n",
        "      if j > 255:\n",
        "        img[x,y] = 255\n",
        "  return img"
      ],
      "metadata": {
        "id": "GoN5KsNuxy8i"
      },
      "id": "GoN5KsNuxy8i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxM6tv5p8rX"
      },
      "outputs": [],
      "source": [
        "def encode_masks(img, img_int):\n",
        "    \"\"\"\n",
        "    Encode img for each class\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    img (np.array): image array\n",
        "\n",
        "    Return:\n",
        "    ------\n",
        "    mask (np.array)\n",
        "    \"\"\"\n",
        "    img = np.squeeze(img).T\n",
        "    img_int = np.squeeze(img_int) * 255\n",
        "\n",
        "    for x,y in [(x,y) for x in range(img_int.shape[0]) for y in range(img_int.shape[1])]:\n",
        "        j = img_int[x,y]\n",
        "        if j > 255:\n",
        "          img_int[x,y] = 255\n",
        "        elif j in range(1,5):\n",
        "          img_int[x,y] = 5\n",
        "        else:\n",
        "          img_int[x,y] = img_int[x,y] \n",
        "\n",
        "    \n",
        "    dim = len(img.shape)\n",
        "    if dim == 2:\n",
        "      # on ramène toutes les valeurs de pixel représentant le foie (1,4) à 1 pour que après le resize on puisse différencier la lésion qui aura pour valeur de pixel 2\n",
        "      for x,y in [(x,y) for x in range(img.shape[0]) for y in range(img.shape[1])]:\n",
        "              j = img[x,y]\n",
        "              if j == 4 or j == 1:\n",
        "                img[x,y] = 1\n",
        "              else:\n",
        "                img[x,y] = img[x,y] \n",
        "      img = resize(img, (IMAGE_HEIGHT, IMAGE_WIDHT), Image.NEAREST, mode = 'constant', preserve_range = True)\n",
        "\n",
        "      mask = np.zeros((img.shape[0], img.shape[1], NUM_CLASSES))\n",
        "      mask[:, :, 0] = img_int\n",
        "      # mask[:, :, 1] = img_int\n",
        "      # mask[:, :, 2] = img_int\n",
        "      # mask[:, :, 3] = img_int\n",
        "\n",
        "      for x,y in [(x,y) for x in range(img.shape[0]) for y in range(img.shape[1])]:\n",
        "        j = img[x,y]\n",
        "        if j == 0:\n",
        "          k = 0\n",
        "        elif j < 2 and j > 0:\n",
        "          k = 1\n",
        "        elif j >=2:\n",
        "          k = 2\n",
        "\n",
        "\n",
        "\n",
        "        # Vide\n",
        "        # if k == 0:\n",
        "        #   mask[x, y, 0] = 0\n",
        "        #   mask[x, y, 1] = 0\n",
        "        #   mask[x, y, 2] = 0\n",
        "        # Lésion\n",
        "        if k > 1:\n",
        "          mask[x, y, 0] = 0\n",
        "          mask[x, y, 1] = 0\n",
        "          mask[x, y, 2] = 1\n",
        "          # mask[x, y, 3] = 0\n",
        "        # Foie\n",
        "        elif k == 1:\n",
        "          mask[x, y, 0] = 0\n",
        "          mask[x, y, 1] = 1\n",
        "          mask[x, y, 2] = 0\n",
        "          # mask[x, y, 3] = 0\n",
        "\n",
        "    elif dim == 3:\n",
        "      mask = np.zeros((img.shape[0], img.shape[1], NUM_CLASSES))\n",
        "      mask[:, :, 0] = img_int\n",
        "      # mask[:, :, 1] = img_int\n",
        "      # mask[:, :, 2] = img_int\n",
        "      # mask[:, :, 3] = img_int\n",
        "      \n",
        "      # on ramène toutes les valeurs de pixel représentant le foie (1,4) à 1 pour que après le resize on puisse différencier la lésion qui aura pour valeur de pixel 2\n",
        "      for x,y in [(x,y) for x in range(img.shape[1]) for y in range(img.shape[2])]:\n",
        "        j = img[0,x,y]\n",
        "        p = img[1,x,y]\n",
        "        j += p\n",
        "        if j == 4 or j == 1:\n",
        "          img[0,x,y] = 0\n",
        "          img[1,x,y] = 1\n",
        "        else:\n",
        "          img[0,x,y] = img[0,x,y]\n",
        "          img[1,x,y] = img[1,x,y]\n",
        "      img = resize(img, (IMAGE_HEIGHT, IMAGE_WIDHT), Image.NEAREST, mode = 'constant', preserve_range = True)\n",
        "\n",
        "      for x,y in [(x,y) for x in range(img.shape[1]) for y in range(img.shape[2])]:\n",
        "        j = img[0,x,y]\n",
        "        p = img[1,x,y]\n",
        "        j += p\n",
        "\n",
        "        if j == 0:\n",
        "          k = 0\n",
        "        elif j <2  and j > 0:\n",
        "          k = 1\n",
        "        elif j >=2:\n",
        "          k = 2\n",
        "\n",
        "        # Vide\n",
        "        # if k == 0:\n",
        "        #   mask[x, y, 0] = 0\n",
        "        #   mask[x, y, 1] = 0\n",
        "        #   mask[x, y, 2] = 0\n",
        "        # Lésion\n",
        "        if k > 1:\n",
        "          mask[x, y, 0] = 0\n",
        "          mask[x, y, 1] = 0\n",
        "          mask[x, y, 2] = 1\n",
        "          # mask[x, y, 3] = 0\n",
        "        # Foie\n",
        "        elif k == 1:\n",
        "          mask[x, y, 0] = 0\n",
        "          mask[x, y, 1] = 1\n",
        "          mask[x, y, 2] = 0\n",
        "          # mask[x, y, 3] = 0\n",
        "    mask /= 255\n",
        "    return mask"
      ],
      "id": "1zxM6tv5p8rX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z82Ll9uvPcgM"
      },
      "outputs": [],
      "source": [
        "def encode_preds(img):\n",
        "    \"\"\"\n",
        "    Encode img_final pred for each class\n",
        "    black for nothing\n",
        "    green for the liver\n",
        "    purple for the lesion \n",
        "    red for the rib cage section\n",
        "    \n",
        "    Parameters:\n",
        "    ----------\n",
        "    img (np.array): image array\n",
        "\n",
        "    Return:\n",
        "    ------\n",
        "    img_final (np.array)\n",
        "    \"\"\"\n",
        "    img = img * 255\n",
        "    img = img.astype(int)\n",
        "    for x,y in [(x,y) for x in range(img.shape[0]) for y in range(img.shape[1])]:\n",
        "          j = img[x,y,0]\n",
        "          if j > 15:\n",
        "            img[x,y,0] = 1\n",
        "          else:\n",
        "            img[x,y,0] = 0\n",
        "\n",
        "    img_final = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "    for x,y in [(x,y) for x in range(img.shape[0]) for y in range(img.shape[1])]:\n",
        "      if img[x,y,0] == 0 and img[x,y,1] == 1 and img[x,y,2] == 0:\n",
        "      # if img[x,y,0] == 2:\n",
        "        img_final[x,y,0] = 104\n",
        "        img_final[x,y,1] = 255\n",
        "        img_final[x,y,2] = 51\n",
        "      elif img[x,y,0] == 0 and img[x,y,1] == 0 and img[x,y,2] == 1:\n",
        "      # elif img[x,y,0] == 3:\n",
        "        img_final[x,y,0] = 138\n",
        "        img_final[x,y,1] = 51\n",
        "        img_final[x,y,2] = 255\n",
        "      elif img[x,y,0] == 1 and img[x,y,1] == 0 and img[x,y,2] == 0:\n",
        "      # elif img[x,y,0] == 1:\n",
        "        img_final[x,y,0] =  49\n",
        "        img_final[x,y,1] =  79\n",
        "        img_final[x,y,2] =  79\n",
        "    return img_final / 255"
      ],
      "id": "z82Ll9uvPcgM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZJliYkpfKnx"
      },
      "outputs": [],
      "source": [
        "def jacard_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)"
      ],
      "id": "HZJliYkpfKnx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJMXowv0wD6w"
      },
      "outputs": [],
      "source": [
        "def plot_sample(X, y, preds, ix=None):\n",
        "    \"\"\"Function to plot the results\"\"\"\n",
        "    if ix is None:\n",
        "        ix = random.randint(1, len(X)) -1\n",
        "\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(10, 10))\n",
        "    ax[0].imshow(X[ix, ..., 0], cmap=plt.cm.gray)\n",
        "    ax[0].set_title('X')\n",
        "\n",
        "    ax[1].imshow(encode_preds(y[ix]).squeeze(), cmap=plt.cm.gray, interpolation='nearest')\n",
        "    ax[1].set_title('Y')\n",
        "\n",
        "    ax[2].imshow(encode_preds(preds[ix]).squeeze(), cmap=plt.cm.gray, interpolation='nearest')\n",
        "    ax[2].set_title('Predicted')\n",
        "    \n",
        "    colors = ['green','purple', 'darkslategray']\n",
        "\n",
        "    labels = [\"foie\", \"lésion\", \"cage\"]\n",
        "\n",
        "    patches = [mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n",
        "\n",
        "    plt.legend(\n",
        "                handles=patches,\n",
        "                bbox_to_anchor=(1.1, 0.65),\n",
        "                loc=2,\n",
        "                borderaxespad=0.4,\n",
        "                fontsize=14,\n",
        "                title=\"Mask Labels\",\n",
        "                title_fontsize=14,\n",
        "                edgecolor=\"black\",\n",
        "                facecolor=\"#c5c6c7\",\n",
        "            )"
      ],
      "id": "NJMXowv0wD6w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ilaUByKgzuu"
      },
      "source": [
        "# Exploration des données"
      ],
      "id": "4ilaUByKgzuu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Kpe5o7pOwv"
      },
      "source": [
        "## Création d'une dataframe à partir de listes"
      ],
      "id": "J0Kpe5o7pOwv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J06DEfkxFUjH"
      },
      "outputs": [],
      "source": [
        "list_patient = []\n",
        "list_input = []\n",
        "list_output = []\n",
        "list_input_resized_scaled = []\n",
        "list_output_resized_scaled = []\n",
        "list_input_shape = []\n",
        "list_output_shape = []\n",
        "list_number_coupe = []\n",
        "list_indice_coupe = []\n",
        "list_number_distinct_pixel_output = []\n",
        "patient_number = 1\n",
        "for file in os.listdir(INPUTS_PATH)[:3]:\n",
        "  path_output = OUTPUTS_PATH + '/Patient ' + file +'.nrrd'\n",
        "  path_input_dir = INPUTS_PATH + '/'+ file\n",
        "  data, header = nd.read(path_output)\n",
        "  number_coupe = data.shape[-1] \n",
        "  dim_output = len(data.shape)\n",
        "  \n",
        "  print(\"\\nPatient n°: \", patient_number)\n",
        "  print(\"Processing données patient n°: \", file)\n",
        "  print(\"Dimension de l'image\", data.shape)\n",
        "  print(f'{number_coupe} coupes')\n",
        "  patient_number +=1\n",
        "\n",
        "  if dim_output == 3:\n",
        "      for coupe in range(number_coupe):\n",
        "        print(f'Coupe n°: {coupe + 1}')\n",
        "        for input in os.listdir(path_input_dir):\n",
        "            if str(coupe+1) == input.split(\".\")[-2].replace(\"Img\", \"\"):\n",
        "              path_input = path_input_dir + '/' + input\n",
        "              input = dcmread(path_input).pixel_array\n",
        "              list_input.append(input)\n",
        "              list_input_shape.append(input.shape)\n",
        "\n",
        "              input_resized_scaled = (resize(encode_inputs(input), (IMAGE_HEIGHT, IMAGE_WIDHT, 1), Image.NEAREST, mode = 'constant', preserve_range = True)) / 255\n",
        "              list_input_resized_scaled.append(input_resized_scaled)\n",
        "              \n",
        "              output = (data[:, :, coupe]).T\n",
        "              list_number_distinct_pixel_output.append(np.unique(output, return_counts=True)[0].shape[0])\n",
        "              list_output.append(output)\n",
        "              list_output_shape.append(output.shape)\n",
        "\n",
        "              output_resized_scaled = encode_masks(data[:, :, coupe], input_resized_scaled)\n",
        "              list_output_resized_scaled.append(output_resized_scaled)\n",
        "              list_patient.append(file)\n",
        "              list_number_coupe.append(number_coupe)\n",
        "              list_indice_coupe.append(coupe+1)\n",
        "\n",
        "  elif dim_output != 3:\n",
        "\n",
        "      for coupe in range(number_coupe):\n",
        "        print(f'Coupe n°: {coupe + 1}')\n",
        "        for input in os.listdir(path_input_dir):\n",
        "            if str(coupe+1) == input.split(\".\")[-2].replace(\"Img\", \"\"):\n",
        "              path_input = path_input_dir + '/' + input\n",
        "              input = dcmread(path_input).pixel_array\n",
        "              list_input.append(input)\n",
        "              list_input_shape.append(input.shape)\n",
        "\n",
        "              input_resized_scaled = (resize(encode_inputs(input), (IMAGE_HEIGHT, IMAGE_WIDHT, 1), Image.NEAREST, mode = 'constant', preserve_range = True)) / 255\n",
        "              list_input_resized_scaled.append(input_resized_scaled)\n",
        "              \n",
        "              data[1, :, :, coupe] = data[0, :, :, coupe] + data[1, :, :, coupe]\n",
        "              output = (data[1, :, :, coupe]).T\n",
        "              list_number_distinct_pixel_output.append(np.unique(output, return_counts=True)[0].shape[0])\n",
        "              list_output.append(output)\n",
        "              list_output_shape.append(data[:, :, :, coupe].shape)\n",
        "\n",
        "              output_resized_scaled = (encode_masks(data[1, :, :, coupe], input_resized_scaled))\n",
        "              list_output_resized_scaled.append(output_resized_scaled)\n",
        "              list_patient.append(file)\n",
        "              list_number_coupe.append(number_coupe)\n",
        "              list_indice_coupe.append(coupe+1)\n",
        "  print(\"Fini\")             "
      ],
      "id": "J06DEfkxFUjH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YWA4mMoFEcW"
      },
      "outputs": [],
      "source": [
        "len(list_patient), len(list_input), len(list_input_shape), len(list_output), len(list_number_distinct_pixel_output), len(list_output_shape), \\\n",
        "len(list_indice_coupe), len(list_number_coupe), len(list_output_resized_scaled), len(list_input_resized_scaled)"
      ],
      "id": "1YWA4mMoFEcW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5buV9IlFUlW"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"Patients\": list_patient,\n",
        "                   \"Inputs\": list_input,\n",
        "                   \"Outputs\": list_output,\n",
        "                   \"Number_distincts_pixel_output\": list_number_distinct_pixel_output,\n",
        "                   \"Input_shape\": list_input_shape,\n",
        "                   \"Outputs_shape\": list_output_shape,\n",
        "                   \"Indices_coupe\": list_indice_coupe,\n",
        "                  \"Number_coupe\": list_number_coupe,\n",
        "                  \"Inputs_resized_scaled\": list_input_resized_scaled,\n",
        "                  \"Outputs_resized_scaled\": list_output_resized_scaled\n",
        "                  })\n",
        "\n",
        "df[\"Patients\"] = df[\"Patients\"].astype(int)\n",
        "df = df.sort_values(by=[\"Patients\", \"Indices_coupe\"], ignore_index=True)\n",
        "df"
      ],
      "id": "g5buV9IlFUlW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ2nejg1pHGx"
      },
      "source": [
        "## Visualisation de scanner"
      ],
      "id": "kZ2nejg1pHGx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuAsf0D5oKr9"
      },
      "outputs": [],
      "source": [
        "# 100 premières coupes\n",
        "for indice_patient in range(len(df[:100])):\n",
        "# for indice_patient in range(len(df)):\n",
        "  coupe = df.loc[indice_patient, \"Indices_coupe\"]\n",
        "  dim_output = df.loc[indice_patient, \"Outputs_shape\"]\n",
        "  print(\"\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  print(\"Patient: \", df.loc[indice_patient, \"Patients\"])\n",
        "  print(\"Nombre de coupe: \", df.loc[indice_patient, \"Number_coupe\"])\n",
        "  print(\"Coupe n°: \", coupe)\n",
        "  print(\"Output shape: \", df.loc[indice_patient, \"Outputs_shape\"])\n",
        "\n",
        "  input = df.loc[indice_patient, \"Inputs\"]\n",
        "\n",
        "  print(\"Input shape: \", input.shape)\n",
        "  # print(\"Nombre de valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0].shape[0])\n",
        "  # print(\"Valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0])\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 1)\n",
        "  plt.imshow(input, cmap=plt.cm.gray)\n",
        "  plt.title(\"Input\")\n",
        "\n",
        "  output = df.loc[indice_patient, \"Outputs\"]\n",
        "  # On regarde la distribution des pixels\n",
        "  intensity_pixel_output = {}\n",
        "  uniques,counts = np.unique(output,return_counts=True)\n",
        "  pixel_output = dict(zip( uniques,counts))\n",
        "  for key,value in pixel_output.items():\n",
        "    try:\n",
        "      intensity_pixel_output[key] += value\n",
        "    except KeyError :\n",
        "      intensity_pixel_output[key] = value\n",
        "  intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 6)\n",
        "  plt.title(\"Distribution des pixels\")\n",
        "  plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "\n",
        "  print(\"Nombre de valeurs distinctes de pixel Mask: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "  print(\"Valeurs distinctes de pixel Mask: \", np.unique(output,return_counts=True)[0])\n",
        "  # print(\"Valeurs distinctes de pixel output: \", np.unique(output,return_counts=True))\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 2)\n",
        "  plt.imshow(output, cmap=plt.cm.gray)\n",
        "  plt.title(\"Mask\")\n",
        "\n",
        "  # Après resize\n",
        "  output = resize(output, (IMAGE_HEIGHT, IMAGE_WIDHT), Image.NEAREST, mode = 'constant', preserve_range = True)\n",
        "  # On regarde la distribution des pixels\n",
        "  intensity_pixel_output = {}\n",
        "  uniques,counts = np.unique(output,return_counts=True)\n",
        "  pixel_output = dict(zip( uniques,counts))\n",
        "  for key,value in pixel_output.items():\n",
        "    try:\n",
        "      intensity_pixel_output[key] += value\n",
        "    except KeyError :\n",
        "      intensity_pixel_output[key] = value\n",
        "  intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 7)\n",
        "  plt.title(\"Distribution des pixels\")\n",
        "  plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "\n",
        "  print(\"Nombre de valeurs distinctes de pixel mask après resize: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "  print(\"Valeurs distinctes de pixel mask après resize: \", np.unique(output,return_counts=True)[0])\n",
        "  # print(\"Valeurs distinctes de pixel mask après resize: \", np.unique(output,return_counts=True))\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 3)\n",
        "  plt.imshow(output, cmap=plt.cm.gray)\n",
        "  plt.title(\"Mask après resize\")\n",
        "\n",
        "  # final\n",
        "  output = encode_preds(df.loc[indice_patient, \"Outputs_resized_scaled\"])\n",
        "  # On regarde la distribution des pixels\n",
        "  intensity_pixel_output = {}\n",
        "  uniques,counts = np.unique(output,return_counts=True)\n",
        "  pixel_output = dict(zip( uniques,counts))\n",
        "  for key,value in pixel_output.items():\n",
        "    try:\n",
        "      intensity_pixel_output[key] += value\n",
        "    except KeyError :\n",
        "      intensity_pixel_output[key] = value\n",
        "  intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 8)\n",
        "  plt.title(\"Distribution des pixels\")\n",
        "  plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "\n",
        "  print(\"Nombre de valeurs distinctes de pixel Output: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "  # print(\"Valeurs distinctes de pixel Output: \", np.unique(output,return_counts=True)[0])\n",
        "  # print(\"Valeurs distinctes de pixel Output: \", np.unique(output,return_counts=True))\n",
        "  fig = plt.figure(1, figsize=(12,12))\n",
        "  plt.subplot(2, 4, 4)\n",
        "  plt.imshow(output, interpolation='nearest')\n",
        "  plt.title(\"Output\")\n",
        "\n",
        "  colors = ['green','purple', 'darkslategray']\n",
        "\n",
        "  labels = [\"foie\", \"lésion\", \"cage\"]\n",
        "\n",
        "  patches = [mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n",
        "\n",
        "  plt.legend(\n",
        "              handles=patches,\n",
        "              bbox_to_anchor=(1.1, 0.65),\n",
        "              loc=2,\n",
        "              borderaxespad=0.4,\n",
        "              fontsize=14,\n",
        "              title=\"Mask Labels\",\n",
        "              title_fontsize=14,\n",
        "              edgecolor=\"black\",\n",
        "              facecolor=\"#c5c6c7\",\n",
        "          )\n",
        "\n",
        "  plt.show()"
      ],
      "id": "nuAsf0D5oKr9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS0wgwBbFUq9"
      },
      "outputs": [],
      "source": [
        "file = 25\n",
        "path_output = OUTPUTS_PATH + '/Patient ' + str(file) +'.nrrd'\n",
        "path_input_dir = INPUTS_PATH + '/'+ str(file)\n",
        "data, header = nd.read(path_output)\n",
        "number_coupe = data.shape[-1] \n",
        "dim_output = len(data.shape)\n",
        "# Chaque patient a différent coupe donc on va parcourir les coupes en entrées et en sorties pour chaque patient en faisant la correspondance entre les deux\n",
        "for coupe in range(number_coupe):\n",
        "  print(\"\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  print(\"Patient: \", file)\n",
        "  print(\"Nombre de coupe: \", number_coupe)\n",
        "  print(\"Coupe n°: \", coupe+1)\n",
        "  print(\"Output shape: \", data.shape)\n",
        "  \n",
        "  for input in os.listdir(path_input_dir):\n",
        "      if dim_output == 3:\n",
        "        if str(coupe+1) == input.split(\".\")[-2].replace(\"Img\", \"\"):\n",
        "          path_input = path_input_dir + '/' + input\n",
        "          input = dcmread(path_input).pixel_array\n",
        "\n",
        "          print(\"Input shape: \", input.shape)\n",
        "          # print(\"Nombre de valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0].shape[0])\n",
        "          # print(\"Valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0])\n",
        "          fig = plt.figure(1, figsize=(10,10))\n",
        "          plt.subplot(2, 2, 1)\n",
        "          plt.imshow(input, cmap=plt.cm.gray)\n",
        "          plt.title(\"Input\")\n",
        "\n",
        "          output = data[:, :, coupe].T\n",
        "          # On regarde la distribution des pixels\n",
        "          intensity_pixel_output = {}\n",
        "          uniques,counts = np.unique(output,return_counts=True)\n",
        "          pixel_output = dict(zip( uniques,counts))\n",
        "          for key,value in pixel_output.items():\n",
        "            try:\n",
        "              intensity_pixel_output[key] += value\n",
        "            except KeyError :\n",
        "              intensity_pixel_output[key] = value\n",
        "          intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "          fig = plt.figure(1, figsize=(10,10))\n",
        "          plt.subplot(2, 2, 4)\n",
        "          plt.title(\"Distribution des pixels\")\n",
        "          plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "\n",
        "          print(\"Nombre de valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "          print(\"Valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0])\n",
        "          fig = plt.figure(1, figsize=(10,10))\n",
        "          plt.subplot(2, 2, 2)\n",
        "          plt.imshow(output, cmap=plt.cm.gray)\n",
        "          plt.title(\"Mask\")\n",
        "\n",
        "          \n",
        "        \n",
        "          \n",
        "\n",
        "      elif dim_output != 3:\n",
        "          if str(coupe+1) == input.split(\".\")[-2].replace(\"Img\", \"\"):\n",
        "            path_input = path_input_dir + '/' + input\n",
        "            input = dcmread(path_input).pixel_array\n",
        "\n",
        "            print(\"Input shape: \", input.shape)\n",
        "            # print(\"Nombre de valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0].shape[0])\n",
        "            # print(\"Valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0])\n",
        "            fig = plt.figure(1, figsize=(10,10))\n",
        "            plt.subplot(2, 2, 1)\n",
        "            plt.imshow(input, cmap=plt.cm.gray)\n",
        "            plt.title(\"Input\")\n",
        "\n",
        "          \n",
        "            data[1, :, :, coupe] = data[0, :, :, coupe] + data[1, :, :, coupe]\n",
        "            output = data[1, :, :, coupe].T\n",
        "            # On regarde la distribution des pixels\n",
        "            intensity_pixel_output = {}\n",
        "            uniques,counts = np.unique(output,return_counts=True)\n",
        "            pixel_output = dict(zip( uniques,counts))\n",
        "            for key,value in pixel_output.items():\n",
        "              try:\n",
        "                intensity_pixel_output[key] += value\n",
        "              except KeyError :\n",
        "                intensity_pixel_output[key] = value\n",
        "            intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "            fig = plt.figure(1, figsize=(10,10))\n",
        "            plt.subplot(2, 2, 4)\n",
        "            plt.title(\"Distribution des pixels\")\n",
        "            plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "            # On regarde la distribution des pixels\n",
        "            print(\"Nombre de valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "            print(\"Valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0])\n",
        "            fig = plt.figure(1, figsize=(10,10))\n",
        "            plt.subplot(2, 2, 2)\n",
        "            plt.imshow(output, cmap=plt.cm.gray)\n",
        "            plt.title(\"Mask\")\n",
        "          \n",
        "\n",
        "      \n",
        "      plt.show()"
      ],
      "id": "bS0wgwBbFUq9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk3KzHOsqSuz"
      },
      "outputs": [],
      "source": [
        "file = 40\n",
        "path_output = OUTPUTS_PATH + '/Patient ' + str(file) +'.nrrd'\n",
        "path_input_dir = INPUTS_PATH + '/'+ str(file)\n",
        "data, header = nd.read(path_output)\n",
        "number_coupe = data.shape[-1] \n",
        "dim_output = len(data.shape)\n",
        "# Chaque patient a différent coupe donc on va parcourir les coupes en entrées et en sorties pour chaque patient en faisant la correspondance entre les deux\n",
        "for coupe in range(number_coupe):\n",
        "  print(\"\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  print(\"Patient: \", file)\n",
        "  print(\"Nombre de coupe: \", number_coupe)\n",
        "  print(\"Coupe n°: \", coupe+1)\n",
        "  print(\"Output shape: \", data.shape)\n",
        "  \n",
        "  for input in os.listdir(path_input_dir):\n",
        "      if dim_output == 3:\n",
        "        if str(coupe+1) == input.split(\".\")[-2].replace(\"Img\", \"\"):\n",
        "          path_input = path_input_dir + '/' + input\n",
        "          input = dcmread(path_input).pixel_array\n",
        "\n",
        "          print(\"Input shape: \", input.shape)\n",
        "          # print(\"Nombre de valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0].shape[0])\n",
        "          # print(\"Valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0])\n",
        "          fig = plt.figure(1, figsize=(10,10))\n",
        "          plt.subplot(2, 2, 1)\n",
        "          plt.imshow(input, cmap=plt.cm.gray)\n",
        "          plt.title(\"Input\")\n",
        "\n",
        "          output = data[:, :, coupe].T\n",
        "          # On regarde la distribution des pixels\n",
        "          intensity_pixel_output = {}\n",
        "          uniques,counts = np.unique(output,return_counts=True)\n",
        "          pixel_output = dict(zip( uniques,counts))\n",
        "          for key,value in pixel_output.items():\n",
        "            try:\n",
        "              intensity_pixel_output[key] += value\n",
        "            except KeyError :\n",
        "              intensity_pixel_output[key] = value\n",
        "          intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "          fig = plt.figure(1, figsize=(10,10))\n",
        "          plt.subplot(2, 2, 4)\n",
        "          plt.title(\"Distribution des pixels\")\n",
        "          plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "\n",
        "          print(\"Nombre de valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "          print(\"Valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0])\n",
        "          fig = plt.figure(1, figsize=(10,10))\n",
        "          plt.subplot(2, 2, 2)\n",
        "          plt.imshow(output, cmap=plt.cm.gray)\n",
        "          plt.title(\"Mask\")\n",
        "\n",
        "      \n",
        "          \n",
        "\n",
        "      elif dim_output != 3:\n",
        "          if str(coupe+1) == input.split(\".\")[-2].replace(\"Img\", \"\"):\n",
        "            path_input = path_input_dir + '/' + input\n",
        "            input = dcmread(path_input).pixel_array\n",
        "\n",
        "            print(\"Input shape: \", input.shape)\n",
        "            # print(\"Nombre de valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0].shape[0])\n",
        "            # print(\"Valeurs distinctes de pixel input: \", np.unique(input,return_counts=True)[0])\n",
        "            fig = plt.figure(1, figsize=(10,10))\n",
        "            plt.subplot(2, 2, 1)\n",
        "            plt.imshow(input, cmap=plt.cm.gray)\n",
        "            plt.title(\"Input\")\n",
        "\n",
        "         \n",
        "            data[1, :, :, coupe] = data[0, :, :, coupe] + data[1, :, :, coupe]\n",
        "            output = data[1, :, :, coupe].T\n",
        "            # On regarde la distribution des pixels\n",
        "            intensity_pixel_output = {}\n",
        "            uniques,counts = np.unique(output,return_counts=True)\n",
        "            pixel_output = dict(zip( uniques,counts))\n",
        "            for key,value in pixel_output.items():\n",
        "              try:\n",
        "                intensity_pixel_output[key] += value\n",
        "              except KeyError :\n",
        "                intensity_pixel_output[key] = value\n",
        "            intensity_pixel_distribution_output = pd.DataFrame({\"key\": intensity_pixel_output.keys(),\"values\": intensity_pixel_output.values()})\n",
        "            fig = plt.figure(1, figsize=(10,10))\n",
        "            plt.subplot(2, 2, 4)\n",
        "            plt.title(\"Distribution des pixels\")\n",
        "            plt.bar(intensity_pixel_distribution_output[\"key\"], intensity_pixel_distribution_output[\"values\"]/sum(intensity_pixel_distribution_output[\"values\"]))\n",
        "            # On regarde la distribution des pixels\n",
        "            print(\"Nombre de valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0].shape[0])\n",
        "            print(\"Valeurs distinctes de pixel mask: \", np.unique(output,return_counts=True)[0])\n",
        "            fig = plt.figure(1, figsize=(10,10))\n",
        "            plt.subplot(2, 2, 2)\n",
        "            plt.imshow(output, cmap=plt.cm.gray)\n",
        "            plt.title(\"Mask\")\n",
        "\n",
        "      \n",
        "      plt.show()"
      ],
      "id": "Bk3KzHOsqSuz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAklY8DshQMe"
      },
      "source": [
        "# Constitution de la base de donnée train et test"
      ],
      "id": "aAklY8DshQMe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZiibO6YzcSS"
      },
      "outputs": [],
      "source": [
        "X = df[\"Inputs_resized_scaled\"]\n",
        "len(X)"
      ],
      "id": "DZiibO6YzcSS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_HUkRtfMbrZ"
      },
      "outputs": [],
      "source": [
        "Y = df[\"Outputs_resized_scaled\"]\n",
        "len(Y)"
      ],
      "id": "v_HUkRtfMbrZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG7CeiW7unpQ"
      },
      "outputs": [],
      "source": [
        "# Split train and valid\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(np.array([np.array(x) for x in X]), np.array([np.array(y) for y in Y]), test_size=0.2)"
      ],
      "id": "wG7CeiW7unpQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzAUe8gB0qgL"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_valid.shape"
      ],
      "id": "mzAUe8gB0qgL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FIFdAgbhW9V"
      },
      "source": [
        "# Entrainement du modèle"
      ],
      "id": "6FIFdAgbhW9V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yKedjMiu3En"
      },
      "outputs": [],
      "source": [
        "input_img = Input((IMAGE_HEIGHT, IMAGE_WIDHT, 1), name='img')\n",
        "\n",
        "\n",
        "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\", dice_coef, jacard_coef])"
      ],
      "id": "7yKedjMiu3En"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrWgVofou99P"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ],
      "id": "UrWgVofou99P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5qF63HtvAbP"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_dice_coef', patience=10, restore_best_weights=True, verbose=1, mode=\"max\"),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
        "    # ModelCheckpoint('/content/drive/MyDrive/model.h5', monitor='val_jacard_coef', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ],
      "id": "Q5qF63HtvAbP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYIWHKM4vDJX"
      },
      "outputs": [],
      "source": [
        "# data_gen = ImageDataGenerator(\n",
        "#     rotation_range=60,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,\n",
        "#     brightness_range=[0.2,1.0],\n",
        "#     zoom_range=[0.2,0.5],\n",
        "#     featurewise_center=True,\n",
        "#     featurewise_std_normalization=True,\n",
        "#     )\n",
        "\n",
        "# data_gen.fit(X_train)\n",
        "\n",
        "\n",
        "# results = model.fit(data_gen.flow(X_train, y_train, batch_size=64), batch_size=64, epochs=80, callbacks=callbacks,\\\n",
        "#                     validation_data=(X_valid, y_valid))\n",
        "\n",
        "\n",
        "\n",
        "results = model.fit(X_train, y_train, batch_size=32, epochs=80, callbacks=callbacks,\\\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "id": "dYIWHKM4vDJX"
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('/content/drive/MyDrive/Segmentation sémantique/model.h5')"
      ],
      "metadata": {
        "id": "YgECXcWzgFJT"
      },
      "id": "YgECXcWzgFJT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ug4e8urvFtP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve loss\")\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend();"
      ],
      "id": "2Ug4e8urvFtP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsIH3XAKa3KP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve accuracy\")\n",
        "plt.plot(results.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.plot(results.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.plot( np.argmax(results.history[\"val_accuracy\"]), np.max(results.history[\"val_accuracy\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend();"
      ],
      "id": "NsIH3XAKa3KP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2SUru0HkjSu"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve dice_coef\")\n",
        "plt.plot(results.history[\"dice_coef\"], label=\"dice_coef\")\n",
        "plt.plot(results.history[\"val_dice_coef\"], label=\"val_dice_coef\")\n",
        "plt.plot( np.argmax(results.history[\"val_dice_coef\"]), np.max(results.history[\"val_dice_coef\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"dice_coef\")\n",
        "plt.legend();"
      ],
      "id": "B2SUru0HkjSu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VN3hhy4fWxH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve jacard_coef\")\n",
        "plt.plot(results.history[\"jacard_coef\"], label=\"jacard_coef\")\n",
        "plt.plot(results.history[\"val_jacard_coef\"], label=\"val_jacard_coef\")\n",
        "plt.plot( np.argmax(results.history[\"val_jacard_coef\"]), np.max(results.history[\"val_jacard_coef\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"jacard_coef\")\n",
        "plt.legend();"
      ],
      "id": "0VN3hhy4fWxH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnQlD9smvV1P"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "BnQlD9smvV1P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc9qS6mwE4VC"
      },
      "outputs": [],
      "source": [
        "# # load the best model\n",
        "# model.load_weights('/content/drive/MyDrive/model.h5')"
      ],
      "id": "uc9qS6mwE4VC"
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/Segmentation sémantique/model.h5', \n",
        "#                                 custom_objects={\"dice_coef\": dice_coef,\n",
        "#                                                 \"jacard_coef\": jacard_coef}\n",
        "# )"
      ],
      "metadata": {
        "id": "AkKjdFwBA6ks"
      },
      "id": "AkKjdFwBA6ks",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgDmFeG7vZF5"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation set (this must be equals to the best log_loss)\n",
        "model.evaluate(X_valid, y_valid, verbose=1)"
      ],
      "id": "qgDmFeG7vZF5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSDMrJgXva8y"
      },
      "outputs": [],
      "source": [
        "# Predict on train, val and test\n",
        "preds_train1 = model.predict(X_train, verbose=1)\n",
        "preds_val1 = model.predict(X_valid, verbose=1)"
      ],
      "id": "hSDMrJgXva8y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQKH4kSl1jCy"
      },
      "outputs": [],
      "source": [
        "preds_train1.shape"
      ],
      "id": "DQKH4kSl1jCy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-L3vXLv1lcZ"
      },
      "outputs": [],
      "source": [
        "preds_val1.shape"
      ],
      "id": "I-L3vXLv1lcZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNVtTqeMZYD0"
      },
      "source": [
        "## Predictions on training set"
      ],
      "id": "jNVtTqeMZYD0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bVpEj3XZTA1"
      },
      "outputs": [],
      "source": [
        "# Check if training data looks all right\n",
        "for i in range(preds_train1.shape[0]):\n",
        "  print(i)\n",
        "  plot_sample(X_train, y_train, preds_train1, ix=i)\n",
        "  plt.show()\n",
        "  if i >25:\n",
        "    break"
      ],
      "id": "8bVpEj3XZTA1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOhRzKIWZcG5"
      },
      "outputs": [],
      "source": [
        "plot_sample(X_train, y_train, preds_train1)"
      ],
      "id": "gOhRzKIWZcG5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw3PmbjAaDpt"
      },
      "source": [
        "## Predictions on test set"
      ],
      "id": "sw3PmbjAaDpt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmk9chA6ZxTb"
      },
      "outputs": [],
      "source": [
        "# Check if valid data looks all right\n",
        "for i in range(preds_val1.shape[0]):\n",
        "  print(i)\n",
        "  plot_sample(X_valid, y_valid, preds_val1, ix=i)\n",
        "  plt.show()\n",
        "  if i > int(preds_val1.shape[0]/10):\n",
        "    break"
      ],
      "id": "Cmk9chA6ZxTb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3vOKewraHQG"
      },
      "outputs": [],
      "source": [
        "plot_sample(X_valid, y_valid, preds_val1)"
      ],
      "id": "d3vOKewraHQG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0KrP8tfNRy6"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "o0KrP8tfNRy6"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Segmentation_sémantique.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}